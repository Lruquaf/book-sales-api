from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
from datetime import datetime
from database import update_book_sales
from database import books_collection


# G√úNCEL URL
BASE_URL = "https://www.kitapyurdu.com/index.php?route=product/publisher_products/all&sort=pd.name&order=ASC&publisher_id=43&filter_in_stock=1&limit=100&page={}"

# Selenium ba≈ülatma ayarlarƒ±
chrome_options = Options()
chrome_options.add_argument("--headless")
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--window-size=1920x1080")
chrome_options.add_argument("--disable-dev-shm-usage")

def fetch_books():
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)

    page = 1
    total_books_fetched = 0
    isTest = False

    while True:
        url = BASE_URL.format(page)
        print(f"üì° Sayfa {page} taranƒ±yor: {url}")

        driver.get(url)
        time.sleep(5)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        books = soup.find_all("div", {"class": "product-cr"})
        if not books or isTest:
            print("‚úÖ T√ºm kitaplar tarandƒ±, i≈ülem tamamlandƒ±.")
            break

        for book in books:
            try:
                link_element = book.find("a", {"class": "pr-img-link"})
                if link_element and "href" in link_element.attrs:
                    book_data = fetch_book_data(link_element["href"], driver)
                    if book_data:
                        # ‚úÖ Generate and pass date in correct format
                        date = datetime.now().strftime("%d/%m/%Y %H:%M")
                        print(f"üìñ Kitap Bulundu: ISBN: {book_data['isbn']}, Adƒ±: {book_data['name']}, Satƒ±≈ü: {book_data['total_sales']}")
                        update_book_sales(
                            book_data["isbn"],
                            book_data["name"],
                            book_data["total_sales"],
                            book_data.get("author"),
                            book_data.get("price"),
                            book_data.get("stock"),
                            book_data.get("url"),
                            date  # ‚úÖ Pass date correctly
                        )
                        total_books_fetched += 1
                    else:
                        print("‚ùå Kitap verisi √ßekilemedi.")
                else:
                    print("‚ùå Link bulunamadƒ±!")
            except Exception as e:
                print(f"‚ùå Kitap verisi √ßekerken hata olu≈ütu: {e}")

        page += 1

    driver.quit()
    print(f"‚úÖ Toplam {total_books_fetched} kitap ba≈üarƒ±yla g√ºncellendi.")

def fetch_book_data(url, driver):
    driver.get(url)
    time.sleep(3)
    soup = BeautifulSoup(driver.page_source, "html.parser")

    try:
        title = soup.find("h1", {"class": "pr_header__heading"}).text.strip()
        isbn_td = soup.find("td", string="ISBN:")
        isbn = isbn_td.find_next("td").text.strip() if isbn_td else None

        # ‚úÖ Skip only if ISBN is missing
        if not isbn or isbn == "N/A" or isbn.strip() == "":
            print(f"‚è© Kitap atlandƒ± (ISBN yok): {title}")
            return None

        # ‚úÖ Extract total sales (can be None or 0)
        sales_element = soup.find("p", {"class": "purchased"})
        total_sales = None
        if sales_element:
            try:
                total_sales = int(sales_element.text.split()[2].replace(".", ""))
            except (ValueError, IndexError):
                total_sales = None

        # ‚úÖ Extract author safely
        author_element = soup.find("a", {"class": "pr_producers__link"})
        author = author_element.text.strip() if author_element else None

        # ‚úÖ Extract price safely
        price_meta = soup.find("meta", {"itemprop": "price"})
        price = float(price_meta.get("content")) if price_meta else None

        # ‚úÖ Extract stock safely (handles both "10+" and "stokta X √ºr√ºn var")
        try:
            stock_element = soup.find("span", {"class": "stock-info"})
            if stock_element:
                stock_text = stock_element.text.strip()

                # Handle "Stok miktarƒ±: 10+" case
                if "Stok miktarƒ±" in stock_text:
                    stock = stock_text.replace("Stok miktarƒ±: ", "").strip()
                    if stock == "10+":
                        stock = 11
                    else:
                        stock = int(stock) if stock.isdigit() else None

                # Handle "Stokta X √ºr√ºn var" case
                elif "Stokta" in stock_text:
                    stock = stock_text.replace("Stokta ", "").replace(" √ºr√ºn var", "").strip()
                    stock = int(stock) if stock.isdigit() else None
                else:
                    stock = None
            else:
                stock = None
        except Exception as e:
            print(f"‚ùå Stock extraction error: {e}")
            stock = None



        # ‚úÖ No longer skips books with missing fields
        return {
            "isbn": isbn,
            "name": title,
            "author": author,
            "price": price,
            "stock": stock,
            "total_sales": total_sales,  # Allow None or 0
            "url": url
        }

    except Exception as e:
        print(f"‚ùå Hata: {e}")
        return None


